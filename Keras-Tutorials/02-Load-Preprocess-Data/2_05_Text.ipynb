{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_05_Text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrp9qOn3p9IU",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow Tutorials\n",
        "# Load and Preprocess Data 05 - Text\n",
        "\n",
        "Using `tf.data.TextLineDataset` to load examples from a text file. This is useful for any dataset which is stored in the form of text files and where each line in the text file is an example (e.g. poetry, error logs, etc.).\n",
        "\n",
        "To demonstrate this API, will be using three different English translations of Homer's Illiad and train a model to identify the translator given a single line of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QKAyALsb7o",
        "colab_type": "text"
      },
      "source": [
        "## Workspace Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPo7lNDQsmrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1e28be2-ad09-4846-c865-197f16f7a7d2"
      },
      "source": [
        "from __future__ import print_function, absolute_import, division, unicode_literals\n",
        "\n",
        "# I want tensorflow 2 because reasons\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Check\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K8kcQQWxH3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset has been built into tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Fill probably need to do some file manipulation\n",
        "import os "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1puS9xHxvpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading preprocessed files for this tutorial\n",
        "DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBpXz9WKx88k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2c723e61-5764-4fc0-aded-ad07e4aaa7a3"
      },
      "source": [
        "# Get each file and store locally\n",
        "for name in FILE_NAMES:\n",
        "  text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name)\n",
        "\n",
        "# Remember the filepath for the directory where these files are stored\n",
        "parent_dir = os.path.dirname(text_dir)\n",
        "\n",
        "# Print this path\n",
        "parent_dir"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
            "819200/815980 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
            "811008/809730 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
            "811008/807992 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_yl4fBeyNEr",
        "colab_type": "text"
      },
      "source": [
        "## Loading into `tf.data.Dataset`\n",
        "Each example needs to be labeled individually, so use `tf.data.Dataset.map` to apply a labeler function to each one. This iterates over all examples in the dataset and reutrns a tuple of the form `(example, label)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSRENPDcydkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labeler(example, index):\n",
        "  return example, tf.cast(index, tf.int64) # cast the index as a 64 bit integer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiKJDzy1ykMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Empty lst to store tuples of labeled datasets\n",
        "labeled_data_sets = []\n",
        "\n",
        "# List of file names is transformed into a list of integer-indexed tuples\n",
        "for i, file_name in enumerate(FILE_NAMES):\n",
        "  # Read each translation as a TextLineDataset by using `join` to get its filepath\n",
        "  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
        "\n",
        "  # Every line in the dataset is passed to the labeler method which returns\n",
        "  # a tuple with the line and the translation's index\n",
        "  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
        "\n",
        "  # Append this dataset of labeled lines to the labeled_data_sets list\n",
        "  labeled_data_sets.append(labeled_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKFWHFtIzN3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine these labeled datasets into a single dataset and shuffle it\n",
        "BUFFER_SIZE = 50000\n",
        "BATCH_SIZE = 64\n",
        "TAKE_SIZE = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-K8Ml0Vzq_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f860a859-d621-4ba9-aeb3-461afc7e495a"
      },
      "source": [
        "labeled_data_sets"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zTmQYSGzU89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Why extract the first element separately?\n",
        "all_labeled_data = labeled_data_sets[0]\n",
        "\n",
        "# Why extract the rest with a for loop?\n",
        "for labeled_dataset in labeled_data_sets[1:]:\n",
        "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
        "\n",
        "# Shuffle, okay, I understand this.\n",
        "all_labeled_data = all_labeled_data.shuffle(\n",
        "    BUFFER_SIZE, reshuffle_each_iteration=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7G1IyYA1YKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a7215661-c84e-42e5-9768-ba8f63ac9292"
      },
      "source": [
        "# Now check the first 5 elements in the newly created list to confirm processing\n",
        "for ex in all_labeled_data.take(5):\n",
        "  print(ex)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: id=74, shape=(), dtype=string, numpy=b'There on the topmost height of Gargarus,'>, <tf.Tensor: id=75, shape=(), dtype=int64, numpy=1>)\n",
            "(<tf.Tensor: id=76, shape=(), dtype=string, numpy=b'Thy joy is ever such, from me apart'>, <tf.Tensor: id=77, shape=(), dtype=int64, numpy=0>)\n",
            "(<tf.Tensor: id=78, shape=(), dtype=string, numpy=b'gods or men.\"'>, <tf.Tensor: id=79, shape=(), dtype=int64, numpy=2>)\n",
            "(<tf.Tensor: id=80, shape=(), dtype=string, numpy=b'Responsive sighs, deploring each, in show,'>, <tf.Tensor: id=81, shape=(), dtype=int64, numpy=0>)\n",
            "(<tf.Tensor: id=82, shape=(), dtype=string, numpy=b'Thou hast thy secret chamber, built for thee'>, <tf.Tensor: id=83, shape=(), dtype=int64, numpy=1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7SjrsQo1pgU",
        "colab_type": "text"
      },
      "source": [
        "## Encoding Text as Numbers\n",
        "ML models do not work on words. They work on numbers. Words in each line of text need to be converted into lists of numbers. To do this, we can map each word in each line to a number in a word_index dictionary of unique words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWkndLLS18-P",
        "colab_type": "text"
      },
      "source": [
        "### Build Vocabulary\n",
        "Tokenize the text into a collection of individual unique words. \n",
        "1. Iterate over each example's numpy value.\n",
        "2. Use `tfds.features.text.Tokenizer` to split it into tokens.\n",
        "3. Collct tokens into a Python **set** to remove duplicates.\n",
        "4. Get the siez of the vocabulary for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IntvF5hn8lUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32dfe2f1-93d1-4b38-94e0-56e5665dbb46"
      },
      "source": [
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "\n",
        "# Ensures no duplicates\n",
        "vocabulary_set = set()\n",
        "\n",
        "# Will only be using the text tensor for each line, don't need the label\n",
        "for text_tensor, _ in all_labeled_data:\n",
        "  # Tokenize using the built in method\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "\n",
        "  # Add the word to the set if not already present\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "# How many unique words across all three translations?\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0n0EQKe89te",
        "colab_type": "text"
      },
      "source": [
        "### Encode Examples \n",
        "Now that individual words have been mapped to unique integers, we can use an **encoder** to transform each sequence of words into a list of integers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrfxEnbv9K2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7cfB3B19N9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1580076-9bca-49b2-ba6c-47bb91667feb"
      },
      "source": [
        "# What does this look like?\n",
        "example_text = next(iter(all_labeled_data))[0].numpy()\n",
        "print(example_text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'There on the topmost height of Gargarus,'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGcM6Gqw9Sv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdb3745d-0861-4b90-ca76-57f9c861e7d2"
      },
      "source": [
        "encoded_example = encoder.encode(example_text)\n",
        "print(encoded_example)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[26, 14281, 2173, 2559, 1941, 14910, 10095]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOWUf2l9cmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the encoder on the entire dataset - wrap this encoder in a tf.py_function and pass it to `map`\n",
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "all_encoded_data = all_labeled_data.map(encode_map_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrkOCxQX9ye5",
        "colab_type": "text"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js-ROVv_92kG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create padded batches - not all lines will have the same number of words (or integers)\n",
        "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1], []))\n",
        "\n",
        "test_data = all_encoded_data.take(TAKE_SIZE)\n",
        "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNEj9mWX-Mtf",
        "colab_type": "text"
      },
      "source": [
        "Now `train_data` and `test_data` are no longer collections of tuples (`examples`, `labels`), but rather collections of **batches** of many such examples and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PZVl_fh-Xwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "32f6c84e-9c9c-4e34-c943-45891408100b"
      },
      "source": [
        "sample_text, sample_labels = next(iter(test_data))\n",
        "sample_text[0], sample_labels[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=99547, shape=(15,), dtype=int64, numpy=\n",
              " array([   26, 14281,  2173,  2559,  1941, 14910, 10095,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])>,\n",
              " <tf.Tensor: id=99551, shape=(), dtype=int64, numpy=1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXBVL28U-bzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0 is now being used for padding so increment vocab size by 1\n",
        "vocab_size += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTat41Sb-rS5",
        "colab_type": "text"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yFSsEzQ-vxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Embedding layer will transform the integers into dense vectors called word embeddings. \n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 64))\n",
        "\n",
        "# LSTM layer - helps model understand context in which words were used\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "\n",
        "# One or more densely connected layers - in this case, 2 layers with 64 units\n",
        "for units in [64, 64]:\n",
        "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
        "\n",
        "# Output layer. First argument is the number of labels\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt3CL3BG_SXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tClDN8-M_zgC",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekgNbHZv_1iU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3a3ee014-ff4a-45bf-9638-dd8c77bf02cb"
      },
      "source": [
        "# Remember, train_data is a generator of batches of labeled lines\n",
        "model.fit(train_data, epochs=3, validation_data=test_data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "697/697 [==============================] - 57s 82ms/step - loss: 0.5226 - accuracy: 0.7418 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "697/697 [==============================] - 47s 68ms/step - loss: 0.2962 - accuracy: 0.8722 - val_loss: 0.3690 - val_accuracy: 0.8280\n",
            "Epoch 3/3\n",
            "697/697 [==============================] - 47s 68ms/step - loss: 0.2260 - accuracy: 0.9004 - val_loss: 0.4192 - val_accuracy: 0.8280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb7ecef9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OEmwO1W_8V-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d03ce1d4-7fcf-40be-de94-e6664d36bb7a"
      },
      "source": [
        "eval_loss, eval_acc = model.evaluate(test_data)\n",
        "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 4s 54ms/step - loss: 0.4192 - accuracy: 0.8280\n",
            "\n",
            "Eval loss: 0.419, Eval accuracy: 0.828\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}