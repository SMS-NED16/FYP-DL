{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Input Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multimodal or multiple input model is a neural network which has two or more independent inputs which are processed by different neural layers. At some point, the outputs of these different layers are combined into a single tensor using a `keras` **merge** operation such as `keras.layers.add`, `keras.layers.concatenate`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Question Answering Model\n",
    "- Inputs are \n",
    "    - A text snippet such as a paragraph or passage containing some information.\n",
    "    - A question posed as a sentence.\n",
    "- These two inputs are independent, but their outputs must be combined. \n",
    "- In the simplest formulation of this problem, the output is a one-word answer obtained via a softmax layer over some predefined vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Constants for the QA Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique words in the information snippet?\n",
    "text_vocabulary_size = 10000    \n",
    "\n",
    "# How many unique words in the question?\n",
    "question_vocabulary_size = 10000\n",
    "\n",
    "# How many unique possible one-word answers?\n",
    "answer_vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Input  \n",
    "\n",
    "The text input will be a variable-length sequence of integers, where each integer encodes one of the unique words in the `text_vocabulary_size` bag of words available. \n",
    "\n",
    "### Steps Involved\n",
    "1. Instantiate a variable-length `text_input` vector which will be composed on integers. Each integer represents on the unique words that can be used to make the information snippet.\n",
    "2. Convert the variable-length `text_input` tensor to a 64-dimensional `embedded_text` tensor using an `Embedding` layer.\n",
    "3. Encode vectors in a single vector using `LSTM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating variable-length tensor of integers called `text`\n",
    "text_input = Input(shape=(None, ), dtype='int32', name='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting variable-length question tensors to a fixed, 64-dimensional vector embedding\n",
    "# This is done by passing the `text_input` tensor as an argument to an `Embedding` layer\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the vectors in a single vector via an LSTM\n",
    "encoded_text = layers.LSTM(32)(embedded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Input \n",
    "\n",
    "We will follow the same steps for converting a variable-length numeric representation of a question (`question_tensor`) into a 32-dimensional vector through an `Embedding` layer, and then encoding all vectors using an `LSTM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating variable-length question tensor\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to 32-dimensional vector embedding\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "encoded_question = layers.LSTM(16)(embedded_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating the Encoded Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = layers.concatenate([encoded_text, encoded_question], \n",
    "                                 axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "The answer will be the result of passing the concatented text and question embeddings to a `Softmax` layer which will predict the probability that that answer to the `question` posed, given the `text`, belongs to one of `answer_vocabulary_size` different words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = layers.Dense(units=answer_vocabulary_size, activation='softmax')(concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model\n",
    "We have transformed a `question_input` and `text_input` tensor into an `answer` tensor by passing them through separate combinations of layers an concatenating their results before passing them to a `concatenate` layer that combines them for prediction over a `Softmax` layer. \n",
    "\n",
    "`keras` will now be able to build a model that links these inputs to our desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([text_input, question_input],    # Input tensors - 2\n",
    "              answer)                          # Output tensor - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           1284224     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           641088      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,909,812\n",
      "Trainable params: 2,909,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "             loss='categorical_crossentropy', \n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model\n",
    "\n",
    "Can either feed the model a list of `numpy` arrays or a dictionary which maps input names - defined with the `name` argument when instantiating `Input`s - to specific `numpy` arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text vectors - `num_samples` vectors, each of size `max_length` i.e the \n",
    "# largest allowable length of words in a `text` input, where each value in the vector\n",
    "# is an integer between 1 and `text_vocabulary_size`\n",
    "text = np.random.randint(1, text_vocabulary_size, \n",
    "                        size=(num_samples, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for questions\n",
    "questions = np.random.randint(1, question_vocabulary_size, \n",
    "                             size=(num_samples, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for answers - answers are one-hot encoded, not integers\n",
    "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a list of numpy tensors as input\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a named dictionary that maps a numpy array to the appropriate `Input` tensors\n",
    "model.fit({'text': text, 'question': question}, answers, \n",
    "         epochs=10, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
