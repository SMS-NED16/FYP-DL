{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python - Chapter 2\n",
    "## 2.2 - Data Representations for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the scalar x:  0\n",
      "Rank of the vector y:  1\n",
      "Rank of the matrix z:  2\n",
      "Rank of array of matrices:  3\n"
     ]
    }
   ],
   "source": [
    "# 0D Tensors - A single scalar or number\n",
    "x = np.array(12)\n",
    "x\n",
    "print(\"Rank of the scalar x: \", x.ndim)\n",
    "\n",
    "# 1D Tensors - Vectors, have one axis, but arbitrarily many dimensions along that axis\n",
    "y = np.array([12, 3, 6, 14])\n",
    "y\n",
    "print('Rank of the vector y: ', y.ndim)\n",
    "\n",
    "# 2D Tensors - Matrices \n",
    "z = np.array([[5, 78, 2, 34, 0], \n",
    "             [5, 78, 2, 34, 0],\n",
    "             [5, 78, 2, 34, 0]])\n",
    "print('Rank of the matrix z: ', z.ndim)\n",
    "\n",
    "# 3D Tensors - interpreted as a cube of numbers\n",
    "tensor_3d = np.array([[[5, 78, 2, 34, 0], \n",
    "             [5, 78, 2, 34, 0],\n",
    "             [5, 78, 2, 34, 0]], \n",
    "            [[5, 78, 2, 34, 0], \n",
    "             [5, 78, 2, 34, 0],\n",
    "             [5, 78, 2, 34, 0]], \n",
    "            [[5, 78, 2, 34, 0], \n",
    "             [5, 78, 2, 34, 0],\n",
    "             [5, 78, 2, 34, 0]]])\n",
    "print('Rank of array of matrices: ', tensor_3d.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Dimensions/Shapes/Data Type in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank of the training images tensor: : 3\n",
      "The rank of the test images tensor:  3\n",
      "The rank of the train labels tensor:  1\n",
      "The rank of the test labels tensor:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"The rank of the training images tensor: :\", train_images.ndim)\n",
    "print(\"The rank of the test images tensor: \", test_images.ndim)\n",
    "print(\"The rank of the train labels tensor: \", train_labels.ndim)\n",
    "print(\"The rank of the test labels tensor: \", test_labels.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of train_images = 3\n",
      "Shape of train_images = (60000, 28, 28)\n",
      "Dtype of train_images = uint8\n",
      "Rank of train_labels = 1\n",
      "Shape of train_labels = (60000,)\n",
      "Dtype of train_labels = uint8\n",
      "Rank of test_images = 3\n",
      "Shape of test_images = (10000, 28, 28)\n",
      "Dtype of test_images = uint8\n",
      "Rank of test_labels = 1\n",
      "Shape of test_labels = (10000,)\n",
      "Dtype of test_labels = uint8\n"
     ]
    }
   ],
   "source": [
    "# For training and test data/labels, printing dimension/rank, shape, and data type of a sample element\n",
    "myDataCollection = {\n",
    "    'train_images': train_images,\n",
    "    'train_labels': train_labels,\n",
    "    'test_images': test_images,\n",
    "    'test_labels': test_labels\n",
    "}\n",
    "\n",
    "for (key, value) in myDataCollection.items():\n",
    "    print(\"Rank of \" + key + ' = ' + str(value.ndim))\n",
    "    print(\"Shape of \" + key + ' = ' + str(value.shape))\n",
    "    print(\"Dtype of \" + key + ' = ' + str(value[0].dtype)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using matplotlib to display a single image\n",
    "digit = train_images[4]\n",
    "\n",
    "# Making necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.viridis)\n",
    "plt.show()\n",
    "\n",
    "# Jupyter Notebook-specific command to display images without explicitly rendering their axes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Selecting digits 10 to 99 from the train_labels array - tensor slicing\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)   # 90 matrices of 28 x 28 unsigned 8 bit integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to a more detailed notation which is \n",
    "my_new_slice = train_images[10:100, :, :] # : means select all elements along this axis\n",
    "print(my_new_slice.shape) # Same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to an even more detailed notation where we explicitly specify start and endpoints\n",
    "my_newer_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_newer_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise relu\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2   # x is a 2D numpy tensor\n",
    "    \n",
    "    # Making a copy of the argument before modification\n",
    "    x = x.copy()\n",
    "    \n",
    "    # For every row in the tensor\n",
    "    for i in range(x.shape[0]):  \n",
    "        # For every column in that row\n",
    "        for j in range(x.shape[1]):\n",
    "            # The new value of x is the maximum value of current element and 0\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x\n",
    "\n",
    "my_matrix = np.array([[1, 2, 3], [4, 5, 6], [-1, -2, 3]])\n",
    "print(naive_relu(my_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [-2 -4  6]]\n"
     ]
    }
   ],
   "source": [
    "# Naive implementation of element-wise addition\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2   # x is a 2D numpy tensor\n",
    "    assert len(y.shape) == 2   # y is also a 2D numpy tensor\n",
    "    \n",
    "    # Make a copy of the x matrix - will be modified - don't want to mutate args\n",
    "    x = x.copy()\n",
    "    # For every row in the matrix\n",
    "    for i in range(x.shape[0]):\n",
    "        # For every column in that row\n",
    "        for j in range(x.shape[1]):\n",
    "            # Add the corresponding element of y\n",
    "            x[i, j] += y[i, j]\n",
    "    return x\n",
    "\n",
    "print(naive_add(my_matrix, my_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "# Can also do this with built-in numpy methods\n",
    "import numpy as np\n",
    "z = my_matrix + my_matrix # element-wise addition\n",
    "z = np.maximum(z, 0)      # relu\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  5 35]\n",
      " [68  8 38]\n",
      " [63  1 35]]\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting - add a matrix and a vector\n",
    "def naive_add_matrix_vector(x, y):\n",
    "    assert len(x.shape) == 2         # x is a 2D numpy tensor - matrix\n",
    "    assert len(y.shape) == 1         # y is a 1D numpy tensor - vector\n",
    "    assert x.shape[1] == y.shape[0]  # columns of matrix = columns of vector \n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):      # for every row in the matrix\n",
    "        for j in range(x.shape[1]):  # and for each element of the vector\n",
    "            x[i, j] += y[j]          # add the elements of the vector to the corresponding elements of that row\n",
    "    return x\n",
    "\n",
    "vector_a = np.array([64, 3, 32])\n",
    "vector_b = np.array([32, 10])\n",
    "\n",
    "print(naive_add_matrix_vector(my_matrix, vector_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 32, 10)\n",
      "(32, 10)\n",
      "(64, 3, 32, 10)\n"
     ]
    }
   ],
   "source": [
    "# Using built-in broadcasting to find maximum value in two tensors of different sizes\n",
    "import numpy as np\n",
    "\n",
    "first_vector = np.random.random((64, 3, 32, 10))\n",
    "second_vector = np.random.random((32, 10))\n",
    "\n",
    "print(first_vector.shape)\n",
    "print(second_vector.shape)\n",
    "element_wise_max = np.maximum(first_vector, second_vector)\n",
    "print(element_wise_max.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.653572663997927\n"
     ]
    }
   ],
   "source": [
    "# Tensor dot operation - two vectors\n",
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1         # x is a numpy vector\n",
    "    assert len(y.shape) == 1         # y is a numpy vector\n",
    "    assert x.shape[0] == y.shape[0]  # same number of elements\n",
    "    z = 0                            # sum s a scalar - element-wise sum\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "\n",
    "first_vector = np.random.rand(10, )\n",
    "second_vector = np.random.rand(10, )\n",
    "print(naive_vector_dot(first_vector, second_vector)) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166. 463.  26.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor dot operation - matrix and vector\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2    # x is a numpy matrix\n",
    "    assert len(y.shape) == 1    # y is a numpy vector\n",
    "    assert x.shape[1] == y.shape[0]   # compatible dimensions\n",
    "    \n",
    "    # Number of elements in each vector (row) of the matrix is the same \n",
    "    # as the number of elements in the vector\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[0]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z\n",
    "\n",
    "print(naive_matrix_vector_dot(my_matrix, vector_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166. 463.  26.]\n"
     ]
    }
   ],
   "source": [
    "# Can also use vector dot operation function in this implementation\n",
    "def improved_naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y) \n",
    "    return z\n",
    "\n",
    "print(improved_naive_matrix_vector_dot(my_matrix, vector_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got the same result as the implementation that uses two for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.   6.  24.]\n",
      " [ 18.  21.  60.]\n",
      " [-12. -18.  -6.]]\n"
     ]
    }
   ],
   "source": [
    "# Arbitrary vector product - between two matrices\n",
    "def naive_matrix_dot(x, y):\n",
    "    # First make sure both x and y are matrices - 2D Numpy tensors\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    \n",
    "    # Also check that the number of cols in x = number of rows in y\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    z = np.zeros((x.shape[0], y.shape[1])) # argument must be a tuple\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            \n",
    "            # A single scalar that is formed by the current row and current column\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z\n",
    "\n",
    "print(naive_matrix_dot(my_matrix, my_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [-1, -2,  3]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Tensor Reshaping\n",
    "x = np.array([[0, 1], [2, 3], [4, 5]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 20)\n",
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "# Transposition\n",
    "x = np.zeros((300, 20))\n",
    "x_transpose = np.zeros((20, 300))\n",
    "print(x.shape)\n",
    "print(x.transpose().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
