{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python\n",
    "# Example 5.2 - Cats and Dogs ConvNet (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the directory where the uncompressed, original dataset is stored\n",
    "original_dataset_dir = '/Users/saads/OneDrive/Desktop/DL-Python/chapter-5/dogs-vs-cats'\n",
    "\n",
    "# This is the new directory where we will be storing the subset of the original dataset\n",
    "base_dir = '/Users/saads/OneDrive/Desktop/DL-Python/chapter-5/cats_and_dogs_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have Python make a new directory at the path specified\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making directories for training, validation, and test splits\n",
    "# Command `join` takes the base_dir path and adds a new folder to this path\n",
    "# Train\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# Test \n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation \n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with validation cat picutres\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with test cat pictures\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with test dog pictures\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training set\n",
    "train_set_dir = os.path.join(original_dataset_dir, 'train')\n",
    "\n",
    "# Path to test set\n",
    "test_set_dir = os.path.join(original_dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Files from the Data Set - Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copies the first 1000 cat images to train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find every file with a name in fnames and copy to the right directory\n",
    "for fname in fnames:\n",
    "    src = os.path.join(train_set_dir, fname)  # source of copy operation\n",
    "    dst = os.path.join(train_cats_dir, fname)       # destination of copy operation\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the next 500 cat images to validation set \n",
    "fnames= ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(train_set_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the next 500 cat images to the test set\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Files From Dataset - Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copies the first 1000 dog images to training set for dogs\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(train_set_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(train_set_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(train_set_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check - Counting Pictures in Each Directory\n",
    "We will count how many pictures are in each training split (tain/test/validation) directory using more functionality of the `os` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Cat Images 1000\n",
      "Total Training Dog Images 1000\n",
      "Total Validation Cat Images 500\n",
      "Total Validation Dog Images 500\n",
      "Total Test Cat Images 500\n",
      "Total Test Dog Images 500\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images'.title(), len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images'.title(), len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images'.title(), len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images'.title(), len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images'.title(), len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images'.title(), len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ConvNet and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# First set of Conv/Pooling\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# Second set of Conv/Pooling\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# Third set of Conv/Pooling\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# Final set of Conv/Pooling\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "\n",
    "# Flattening ConvNet output before it is input to densely connected classifier\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Creating the densely connected classifier\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary - layers, params, trainable params, output shapes\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Network\n",
    "\n",
    "Importing `optimizer` module so we can instantiate an object of this class and set its learning rate to `1e-4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers \n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "1. Read the picture files\n",
    "2. Decode the JPEG content to RGB grids of pixels\n",
    "3. Convert these into floating-point tensors\n",
    "4. Rescalee the pixel values (between 0 and 255) to the [0, 1] interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators that will rescale their elements by 255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,                          # target directory\n",
    "    target_size=(150, 150),             # Resize all images to 150 x 150 arbitrarily\n",
    "    batch_size=20,                      # In batches of 20 images at a time\n",
    "    class_mode='binary'                 # Binary labels for binary crossentropy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Doing the same for the validation set\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir, \n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detour - Pyton Generators\n",
    "\n",
    "A Python generator is an object that acts as an iterator. We can pass the generator to a `for`...`in` statement. The generator will (surprise) generate a value which will then be passed to the for...in loop and can be processed further.\n",
    "\n",
    "The control structure that uses the generator must provide a mechanism to break the infinite stream of values that will be generated by the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customGenerator():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for item in customGenerator():\n",
    "    print(item)\n",
    "    if item > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Batch Shape:  (20, 150, 150, 3)\n",
      "Labels Batch Shape:  (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data Batch Shape: ', data_batch.shape)\n",
    "    print('Labels Batch Shape: ', labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Generators to the Model\n",
    "\n",
    "The `fit_generator` method is a built-in `keras` method that is basically `fit` but with generator arguments. `fit` expects tensors to train a neural network, whereas `fit_generator` expects generator objects.\n",
    "\n",
    "The generator objects (for the training data and the validation data) will yield a batch of inputs and targets indefinitely. Keras needs to know how many sampels to draw from the generator before declaring an epoch over. \n",
    "\n",
    "This is why we must also provide a `steps_per_epoch` argument - how many batches will be drawn from the generator for each epoch. \n",
    "\n",
    "After running `steps_per_epoch` gradient descent steps, the fitting process will go to the next epoch.\n",
    "\n",
    "Validation data argument is allowed to be a generator, but is also allowed to be a tuple of Numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saads\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.6682 - acc: 0.5840\n",
      "100/100 [==============================] - 197s 2s/step - loss: 0.6914 - acc: 0.5420 - val_loss: 0.6682 - val_acc: 0.5840\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.6644 - acc: 0.5770\n",
      "100/100 [==============================] - 210s 2s/step - loss: 0.6648 - acc: 0.5975 - val_loss: 0.6644 - val_acc: 0.5770\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 33s 667ms/step - loss: 0.6537 - acc: 0.5950\n",
      "100/100 [==============================] - 211s 2s/step - loss: 0.6402 - acc: 0.6465 - val_loss: 0.6537 - val_acc: 0.5950\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 31s 616ms/step - loss: 0.6026 - acc: 0.6630\n",
      "100/100 [==============================] - 206s 2s/step - loss: 0.6074 - acc: 0.6755 - val_loss: 0.6026 - val_acc: 0.6630\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.5863 - acc: 0.6810\n",
      "100/100 [==============================] - 217s 2s/step - loss: 0.5628 - acc: 0.7185 - val_loss: 0.5863 - val_acc: 0.6810\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.5748 - acc: 0.6960\n",
      "100/100 [==============================] - 196s 2s/step - loss: 0.5296 - acc: 0.7310 - val_loss: 0.5748 - val_acc: 0.6960\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.5641 - acc: 0.6990\n",
      "100/100 [==============================] - 191s 2s/step - loss: 0.4981 - acc: 0.7640 - val_loss: 0.5641 - val_acc: 0.6990\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.5568 - acc: 0.7100\n",
      "100/100 [==============================] - 199s 2s/step - loss: 0.4755 - acc: 0.7765 - val_loss: 0.5568 - val_acc: 0.7100\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.5440 - acc: 0.7210\n",
      "100/100 [==============================] - 195s 2s/step - loss: 0.4490 - acc: 0.7890 - val_loss: 0.5440 - val_acc: 0.7210\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.5492 - acc: 0.7220\n",
      "100/100 [==============================] - 194s 2s/step - loss: 0.4246 - acc: 0.8070 - val_loss: 0.5492 - val_acc: 0.7220\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.5568 - acc: 0.7200\n",
      "100/100 [==============================] - 198s 2s/step - loss: 0.4002 - acc: 0.8150 - val_loss: 0.5568 - val_acc: 0.7200\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 33s 660ms/step - loss: 0.5520 - acc: 0.7300\n",
      "100/100 [==============================] - 199s 2s/step - loss: 0.3846 - acc: 0.8315 - val_loss: 0.5520 - val_acc: 0.7300\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.5987 - acc: 0.7030\n",
      "100/100 [==============================] - 198s 2s/step - loss: 0.3520 - acc: 0.8445 - val_loss: 0.5987 - val_acc: 0.7030\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.5683 - acc: 0.7340\n",
      "100/100 [==============================] - 219s 2s/step - loss: 0.3283 - acc: 0.8660 - val_loss: 0.5683 - val_acc: 0.7340\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 35s 693ms/step - loss: 0.5798 - acc: 0.7290\n",
      "100/100 [==============================] - 217s 2s/step - loss: 0.3074 - acc: 0.8700 - val_loss: 0.5798 - val_acc: 0.7290\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 38s 766ms/step - loss: 0.5701 - acc: 0.7410\n",
      "100/100 [==============================] - 245s 2s/step - loss: 0.2877 - acc: 0.8860 - val_loss: 0.5701 - val_acc: 0.7410\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 39s 773ms/step - loss: 0.5907 - acc: 0.7340\n",
      "100/100 [==============================] - 230s 2s/step - loss: 0.2647 - acc: 0.8935 - val_loss: 0.5907 - val_acc: 0.7340\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.5972 - acc: 0.7380\n",
      "100/100 [==============================] - 107936s 1079s/step - loss: 0.2553 - acc: 0.8895 - val_loss: 0.5972 - val_acc: 0.7380\n",
      "Epoch 19/30\n",
      "  8/100 [=>............................] - ETA: 2:49 - loss: 0.1903 - acc: 0.9500"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
