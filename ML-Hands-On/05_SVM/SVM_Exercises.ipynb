{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands-on-ML-05-SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3r9HnJ9hg59",
        "colab_type": "text"
      },
      "source": [
        "# Hands-on Machine Learning - Chapter 5 - Support Vector Machines - Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n93Yd_ZChu-o",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 10 - SVM Regressor on California Housing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yKiYGa_ioNw",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c63bbNa6hzDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plotting Imports\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Scikit-imports\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Hutha2iisM",
        "colab_type": "text"
      },
      "source": [
        "## Loading and Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdhxqWo6i97P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F74Q_K2PjBjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3859caf6-5275-47bd-e967-9cecfdb7c246"
      },
      "source": [
        "# Will download this dataset - requires an internet connection\n",
        "housing = fetch_california_housing()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qw8UBcTjCf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "57e9937f-173a-447c-88c4-c1b562b0ccc8"
      },
      "source": [
        "print(housing.DESCR)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4gtuUQ5jHEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting features and targets\n",
        "X = housing['data']\n",
        "y = housing['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MxVxUxVjVVW",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDSppQ_NjXBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UASnBrOpjzNY",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po53mB80j1tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate a StandardScaler\n",
        "standardScaler = StandardScaler()\n",
        "\n",
        "# Find mean and standard deviation for scaling using training data, and then scale it \n",
        "X_train_scaled = standardScaler.fit_transform(X_train) \n",
        "\n",
        "# Use mean and std from training data to transform the test data \n",
        "X_test_scaled = standardScaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P5QJPH5jb09",
        "colab_type": "text"
      },
      "source": [
        "## Simple Linear Support Vector Regressor\n",
        "\n",
        "Linear SVRs have a time complexity that scales almost linearly with both the number of features `n` and the number of samples `m`. So it's worth investigating the performance of a linear support vector machine before we implement more complicated (and resource-intensive) non-linear/kernelized models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TfQZk1tkVei",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83mrkT_rjrwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate\n",
        "linear_svr = LinearSVR(random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHgV4Fi4jw_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "336495f4-f0d0-42dd-8324-61907527e0e0"
      },
      "source": [
        "# Fit to the scaled data\n",
        "linear_svr.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
              "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
              "          random_state=42, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjSkDSmvkSnx",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating - Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o-mVqnBkXOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd52e3f3-eac1-426a-e1fa-dbbc50fc0413"
      },
      "source": [
        "y_pred = linear_svr.predict(X_train_scaled)\n",
        "\n",
        "# Mean Squared Error - useful if there are outliers in the data\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "print(\"MSE on Training Set: {:.5f}\".format(mse))\n",
        "\n",
        "# RMSE Error - In the same units as the actual target, so good for comparison\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"RMSE on Training Set: {:.5f}\".format(rmse))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE on Training Set: 0.94997\n",
            "RMSE on Training Set: 0.97466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMy3sGxYknY-",
        "colab_type": "text"
      },
      "source": [
        "## Kernelized SVM Regressor\n",
        "\n",
        "The `target` of this dataset is the price of a house in tens of thousands of dollars. The RMSE is an error expressed in the same units as the target, and is a measure of the average error between the predictions and targets, with larger 'weightage' for larger errors (due to outliers). \n",
        "\n",
        "The results show that the predicted average error in the price of a house is $0.97466 \\times \\$ 10000 = \\$9746.6$, which means our Linear SVM tends to make prediction errors that are approximately USD 10k higher or lower than the actual price of the house.\n",
        "\n",
        "This is not a good model. Now let's a try a kernelized SVM regressor using the `rbf` function.  \n",
        "\n",
        "Instead of using `GridSearchCV` to find the optimal value of hyperparameters from a list or grid of possible values, we'll use `RandomizedSearchCV` to find the optimal values of hyperparameters in a continuous distribution of possible values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP4z38-4oYxN",
        "colab_type": "text"
      },
      "source": [
        "### Parameter Spaces/Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTP3vuJMlXE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Different kind of continuous distributions for random variables\n",
        "from scipy.stats import reciprocal, uniform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9XMxPwnrge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining distributions for each possible parameter's values\n",
        "param_distributions = {\n",
        "    'gamma': reciprocal(0.001, 0.1), \n",
        "    'C': uniform(1, 10)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMGTfzUdocCZ",
        "colab_type": "text"
      },
      "source": [
        "### Randomized Search for Cross Validation\n",
        "\n",
        "Took 9.0s - 10.5s per fit, 4.6 min for fitting all folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7o-LZAVn4n3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5209140-f986-49b1-d0bf-b0e00e642b34"
      },
      "source": [
        "# Draw 10 random pairs of values for each hyperparam, fit three folds \n",
        "random_search_cv = RandomizedSearchCV(estimator=SVR(), \n",
        "                                      param_distributions=param_distributions, \n",
        "                                      n_iter=10, \n",
        "                                      verbose=2, \n",
        "                                      cv=3, \n",
        "                                      random_state=42)\n",
        "random_search_cv.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=  10.5s\n",
            "[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=  10.5s\n",
            "[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................\n",
            "[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=  10.5s\n",
            "[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................\n",
            "[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   9.9s\n",
            "[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................\n",
            "[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   9.6s\n",
            "[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................\n",
            "[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   9.8s\n",
            "[CV] C=2.560186404424365, gamma=0.002051110418843397 .................\n",
            "[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   8.9s\n",
            "[CV] C=2.560186404424365, gamma=0.002051110418843397 .................\n",
            "[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   8.9s\n",
            "[CV] C=2.560186404424365, gamma=0.002051110418843397 .................\n",
            "[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   9.0s\n",
            "[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................\n",
            "[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   8.9s\n",
            "[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................\n",
            "[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   8.9s\n",
            "[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................\n",
            "[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   8.9s\n",
            "[CV] C=7.011150117432088, gamma=0.026070247583707663 .................\n",
            "[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   9.7s\n",
            "[CV] C=7.011150117432088, gamma=0.026070247583707663 .................\n",
            "[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   9.8s\n",
            "[CV] C=7.011150117432088, gamma=0.026070247583707663 .................\n",
            "[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   9.9s\n",
            "[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................\n",
            "[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   8.6s\n",
            "[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................\n",
            "[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   8.8s\n",
            "[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................\n",
            "[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   8.7s\n",
            "[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................\n",
            "[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   9.1s\n",
            "[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................\n",
            "[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   9.1s\n",
            "[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................\n",
            "[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   8.9s\n",
            "[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................\n",
            "[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   8.9s\n",
            "[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................\n",
            "[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   8.9s\n",
            "[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................\n",
            "[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   9.0s\n",
            "[CV] C=4.042422429595377, gamma=0.011207606211860567 .................\n",
            "[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   9.0s\n",
            "[CV] C=4.042422429595377, gamma=0.011207606211860567 .................\n",
            "[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   9.0s\n",
            "[CV] C=4.042422429595377, gamma=0.011207606211860567 .................\n",
            "[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   9.0s\n",
            "[CV] C=5.319450186421157, gamma=0.003823475224675185 .................\n",
            "[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   8.8s\n",
            "[CV] C=5.319450186421157, gamma=0.003823475224675185 .................\n",
            "[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   9.0s\n",
            "[CV] C=5.319450186421157, gamma=0.003823475224675185 .................\n",
            "[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   9.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
              "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
              "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
              "                                 verbose=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4108efb38>,\n",
              "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff410984b70>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4bVNWZpoGYZ",
        "colab_type": "text"
      },
      "source": [
        "### Best Estimator\n",
        "\n",
        "**Params Found Through Searching**\n",
        "\n",
        "`C` = 4.745401188473625\n",
        "\n",
        "`gamma` = 0.0796954818643928\n",
        "\n",
        "**Default Prameter Values**\n",
        "`cache_size` = 200\n",
        "\n",
        "`coef0` = 0.0\n",
        "\n",
        "`degree` = 3 \n",
        "\n",
        "`epsilon` = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUu6QkGoXdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5726df1e-3274-4219-97e4-4d51f2e8e8ae"
      },
      "source": [
        "# What are the hyperparameters of the best estimator? \n",
        "random_search_cv.best_estimator_"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=4.745401188473625, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
              "    gamma=0.07969454818643928, kernel='rbf', max_iter=-1, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr6QiVFsoqGx",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation - Training Set \n",
        "\n",
        "Ideally, the RMSE on the training set should be lower than that of the linear SVM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v9fJ36Gow29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03cead11-0368-4513-b768-a227336fee05"
      },
      "source": [
        "y_pred_train = random_search_cv.best_estimator_.predict(X_train_scaled)\n",
        "mse = mean_squared_error(y_train, y_pred_train)\n",
        "print(\"RMSE on Training Set: {:.5f}\".format(np.sqrt(mse)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE on Training Set: 0.57275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0uE1nsZpAIR",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation - Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAnB80hspB_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b305ee90-1023-49bf-8f36-19e1779e3f22"
      },
      "source": [
        "y_pred_test = random_search_cv.best_estimator_.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "print(\"RMSE on Test Set: {:.5f}\".format(np.sqrt(mse)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE on Test Set: 0.59292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E_BLYh8pJ-A",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "Using a kernelized SVM regressor (RBF kernel) and carrying out `RandomizedSearch` for its parameters resulted in a model that  ecreased the RMSE on the training set from ~0.97 to ~0.57, which is ~40% improvement. \n",
        "\n",
        "On the test set, this means our errors in housing price predictions are approximately $6,000. While this is far from ideal, it is still an improvement over the linear support vector regressor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HAUzAUvqjoU",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 9 - SVM on MNIST\n",
        "\n",
        "Will require one-versus-all classification since SVMs are binary classifiers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK2vLVphqp2O",
        "colab_type": "text"
      },
      "source": [
        "## Loading and Processing Data\n",
        "\n",
        "Usually, we'd use a function like `train_test_split` to get the training and test data. However, with MNIST, its common practice to use the first 60,000 samples for the training set and the remaining 10,000 samples for the test set. \n",
        "\n",
        "This allows us to compare our results with those of other practitioners. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyvrzraVrDGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml \n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkpm08u1rK9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting features and labels\n",
        "X = mnist['data']\n",
        "y = mnist['target'].astype(np.uint8)    # All labels are 8-bit integers, not floats or strings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2OioNuqrTPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 60k samples for train, remaining 10k for split\n",
        "N_TRAIN = 60000\n",
        "X_train, y_train = X[:N_TRAIN], y[:N_TRAIN]\n",
        "X_test, y_test = X[N_TRAIN:], y[N_TRAIN:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WjKYZyrlH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24075cd5-0dd6-4a43-ff96-7e2547666e9c"
      },
      "source": [
        "# Confirming indexing performed correctly \n",
        "print(\"Training data and label shapes: \", X_train.shape, y_train.shape)\n",
        "print(\"Test data and label shapes: \", X_test.shape, y_test.shape)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data and label shapes:  (60000, 784) (60000,)\n",
            "Test data and label shapes:  (10000, 784) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5XR24Nprsyi",
        "colab_type": "text"
      },
      "source": [
        "No need to shuffle this dataset, because it is already shuffled. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuTMATKWr_tT",
        "colab_type": "text"
      },
      "source": [
        "## Linear SVM Classifier - Without Scaling\n",
        "\n",
        "Will automatically use the one-vs-all strategy (also called one-vs-rest, OvR) for classification, so we don't really need to do anything other than call fit. \n",
        "\n",
        "Deliberately not scaling features for this model to show how poor SVM classification performance can be without proper feature scaling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOpwjQ6GsQg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC, SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPIOpfCtsLOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4ad92079-2583-4035-da3c-30c32dad2a44"
      },
      "source": [
        "# Instantiate a classifier\n",
        "lin_svm_clf = LinearSVC(random_state=42)\n",
        "\n",
        "# Fit to the training data - Before scaling\n",
        "lin_svm_clf.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81q8TdRhsiKz",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Model Performance - Training Set\n",
        "\n",
        "We will not evaluate on the test set because we still have lots of hyperparameter tuning to do, and we don't want to overfit to the test data.\n",
        "\n",
        "In any case, making predictions on the training set will give us an idea of how good - or bad - our model is. If it's score is subpar on data it has already seen before, it will obviously not perform well on untrained data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6sFatnytOu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Kyvrv8tZYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions on the training set \n",
        "y_pred = lin_svm_clf.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xew2yGlKtnm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8215e28-f268-49a9-c8ba-eb73a58234fd"
      },
      "source": [
        "# Accuracy is number of correctly classified samples\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMLrmO4tr4R",
        "colab_type": "text"
      },
      "source": [
        "This is a very poor accuracy, especially for the MNIST problem and especially for the training set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSfY-w1atxKv",
        "colab_type": "text"
      },
      "source": [
        "## Linear SVM Classifier - With Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpodbpSitzgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96LuPTsqt5Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate a StandardScaler\n",
        "standardScaler = StandardScaler() \n",
        "\n",
        "# Fit to the training data to extract means and std for stanardization, then transform training data\n",
        "X_train_scaled = standardScaler.fit_transform(X_train.astype(np.float32))\n",
        "\n",
        "# Transform (but don't fit to) test set\n",
        "X_test_scaled = standardScaler.transform(X_test.astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyZrC0N1STW",
        "colab_type": "text"
      },
      "source": [
        "### Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjBSO4i81duE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ff9e2130-10b8-43f0-8f64-4faa6a1d13bb"
      },
      "source": [
        "lin_clf = LinearSVC(random_state=42)\n",
        "lin_clf.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKsq8xN1j1m",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RijHXpTD1vB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNUtlZLI1oxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b15e820-a264-4e0d-f424-fc06edeb67cd"
      },
      "source": [
        "y_pred = lin_clf.predict(X_train_scaled)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9226833333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5hjNIhW4J7S",
        "colab_type": "text"
      },
      "source": [
        "Objectively, this is a good score. But on MNIST, higher scores are possible. This means we should explore non-linear or kernelized SVMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOuFZvLD1waV",
        "colab_type": "text"
      },
      "source": [
        "## SVC with RBF Kernel \n",
        "\n",
        "Past experiments show that the data is, at least partly, not linearly separable. Will probably get improved performance using a non-linear SVM with kernel function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quH3dLKy190V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiating an SVC with RBF kernel\n",
        "svm_clf = SVC(kernel='rbf', gamma='scale')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHTSqF5j2FEP",
        "colab_type": "text"
      },
      "source": [
        "### Training on Subset \n",
        "\n",
        "The time complexity of a non-linear SVM is much larger than that of a linear SVM. As such, it is more efficient to train and validate the SVM using a smaller subset of the training data. Once optimal hyperparameters have been identified in this way, the final SVM can be trained on the entire training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krh594h82VQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0d9da14c-14e8-4176-8479-23c0f61e9155"
      },
      "source": [
        "N_SAMPLES_SUBSET = 10000\n",
        "svm_clf.fit(X_train_scaled[:N_SAMPLES_SUBSET], y_train[:N_SAMPLES_SUBSET])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EATMWSnr2g7N",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk0MefMA2l3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45bcf4ae-8758-4d1b-94bf-d91229b58559"
      },
      "source": [
        "y_pred = svm_clf.predict(X_train_scaled)\n",
        "accuracy_score(y_pred, y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9455333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfODBcYR2oyV",
        "colab_type": "text"
      },
      "source": [
        "## Kernelized SVM - Hyperparameter Tuning\n",
        "\n",
        "An untuned, unregularized kernelized SVM offers much better performance on the training data than an unregularized linear SVC. \n",
        "\n",
        "This is why hyperparameter tuning of the kernelized SVM may actually be worthwhile. \n",
        "\n",
        "Will once again specify a distribution from which the value of a hyperparameter will be drawn. \n",
        "\n",
        "Will train `n_iter` different models, each of which will draw a different combination of hyperparameter values drawn from the specified distributions. \n",
        "\n",
        "The `RandomizedSearchCV` will then return the best model after training it on the entire data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBbJSFGB3Ubo",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcU-A7pC3bB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diN32OL33ge7",
        "colab_type": "text"
      },
      "source": [
        "### Defining Parameter Distributions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVEqaZ7A3jtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_distributions = {\n",
        "    'gamma': reciprocal(0.001, 0.1),    # Smaller values have higher probabilities of being drawn\n",
        "    'C': uniform(1, 10)                 # All values are equally likely to be drawn\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz2sFRb63zs9",
        "colab_type": "text"
      },
      "source": [
        "### Randomized Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HVrA2eb6BFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_clf = SVC(kernel='rbf', gamma='scale', random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YShbC-r1320m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnd_search_cv = RandomizedSearchCV(svm_clf, \n",
        "                                   param_distributions, \n",
        "                                   n_iter=10, \n",
        "                                   verbose=2,\n",
        "                                   cv=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmlbz3oZ3-NO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "289fb687-0aec-48ae-c879-99259d00e1fd"
      },
      "source": [
        "# Must specify the y_train data too, otherwise won't get best estimator\n",
        "rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] C=4.998609717152554, gamma=0.001239742034078414 .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=4.998609717152554, gamma=0.001239742034078414, total=   0.9s\n",
            "[CV] C=4.998609717152554, gamma=0.001239742034078414 .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=4.998609717152554, gamma=0.001239742034078414, total=   0.9s\n",
            "[CV] C=4.998609717152554, gamma=0.001239742034078414 .................\n",
            "[CV] .. C=4.998609717152554, gamma=0.001239742034078414, total=   0.9s\n",
            "[CV] C=10.737555188414591, gamma=0.002921074818565714 ................\n",
            "[CV] . C=10.737555188414591, gamma=0.002921074818565714, total=   1.1s\n",
            "[CV] C=10.737555188414591, gamma=0.002921074818565714 ................\n",
            "[CV] . C=10.737555188414591, gamma=0.002921074818565714, total=   1.1s\n",
            "[CV] C=10.737555188414591, gamma=0.002921074818565714 ................\n",
            "[CV] . C=10.737555188414591, gamma=0.002921074818565714, total=   1.1s\n",
            "[CV] C=1.906064345328208, gamma=0.017249321573179 ....................\n",
            "[CV] ..... C=1.906064345328208, gamma=0.017249321573179, total=   1.3s\n",
            "[CV] C=1.906064345328208, gamma=0.017249321573179 ....................\n",
            "[CV] ..... C=1.906064345328208, gamma=0.017249321573179, total=   1.3s\n",
            "[CV] C=1.906064345328208, gamma=0.017249321573179 ....................\n",
            "[CV] ..... C=1.906064345328208, gamma=0.017249321573179, total=   1.3s\n",
            "[CV] C=4.824619912671627, gamma=0.09256818992066876 ..................\n",
            "[CV] ... C=4.824619912671627, gamma=0.09256818992066876, total=   1.3s\n",
            "[CV] C=4.824619912671627, gamma=0.09256818992066876 ..................\n",
            "[CV] ... C=4.824619912671627, gamma=0.09256818992066876, total=   1.3s\n",
            "[CV] C=4.824619912671627, gamma=0.09256818992066876 ..................\n",
            "[CV] ... C=4.824619912671627, gamma=0.09256818992066876, total=   1.3s\n",
            "[CV] C=5.667628932479799, gamma=0.05246634533625283 ..................\n",
            "[CV] ... C=5.667628932479799, gamma=0.05246634533625283, total=   1.3s\n",
            "[CV] C=5.667628932479799, gamma=0.05246634533625283 ..................\n",
            "[CV] ... C=5.667628932479799, gamma=0.05246634533625283, total=   1.3s\n",
            "[CV] C=5.667628932479799, gamma=0.05246634533625283 ..................\n",
            "[CV] ... C=5.667628932479799, gamma=0.05246634533625283, total=   1.3s\n",
            "[CV] C=7.803075385877797, gamma=0.007961566078062943 .................\n",
            "[CV] .. C=7.803075385877797, gamma=0.007961566078062943, total=   1.2s\n",
            "[CV] C=7.803075385877797, gamma=0.007961566078062943 .................\n",
            "[CV] .. C=7.803075385877797, gamma=0.007961566078062943, total=   1.2s\n",
            "[CV] C=7.803075385877797, gamma=0.007961566078062943 .................\n",
            "[CV] .. C=7.803075385877797, gamma=0.007961566078062943, total=   1.2s\n",
            "[CV] C=1.1326496115986653, gamma=0.0766308268025585 ..................\n",
            "[CV] ... C=1.1326496115986653, gamma=0.0766308268025585, total=   1.3s\n",
            "[CV] C=1.1326496115986653, gamma=0.0766308268025585 ..................\n",
            "[CV] ... C=1.1326496115986653, gamma=0.0766308268025585, total=   1.3s\n",
            "[CV] C=1.1326496115986653, gamma=0.0766308268025585 ..................\n",
            "[CV] ... C=1.1326496115986653, gamma=0.0766308268025585, total=   1.3s\n",
            "[CV] C=6.632882178455393, gamma=0.005899741796710488 .................\n",
            "[CV] .. C=6.632882178455393, gamma=0.005899741796710488, total=   1.2s\n",
            "[CV] C=6.632882178455393, gamma=0.005899741796710488 .................\n",
            "[CV] .. C=6.632882178455393, gamma=0.005899741796710488, total=   1.3s\n",
            "[CV] C=6.632882178455393, gamma=0.005899741796710488 .................\n",
            "[CV] .. C=6.632882178455393, gamma=0.005899741796710488, total=   1.2s\n",
            "[CV] C=1.159662522202142, gamma=0.0028959272747088377 ................\n",
            "[CV] . C=1.159662522202142, gamma=0.0028959272747088377, total=   1.1s\n",
            "[CV] C=1.159662522202142, gamma=0.0028959272747088377 ................\n",
            "[CV] . C=1.159662522202142, gamma=0.0028959272747088377, total=   1.1s\n",
            "[CV] C=1.159662522202142, gamma=0.0028959272747088377 ................\n",
            "[CV] . C=1.159662522202142, gamma=0.0028959272747088377, total=   1.1s\n",
            "[CV] C=3.410254660260117, gamma=0.023255572624036783 .................\n",
            "[CV] .. C=3.410254660260117, gamma=0.023255572624036783, total=   1.3s\n",
            "[CV] C=3.410254660260117, gamma=0.023255572624036783 .................\n",
            "[CV] .. C=3.410254660260117, gamma=0.023255572624036783, total=   1.3s\n",
            "[CV] C=3.410254660260117, gamma=0.023255572624036783 .................\n",
            "[CV] .. C=3.410254660260117, gamma=0.023255572624036783, total=   1.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   35.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                                 class_weight=None, coef0=0.0,\n",
              "                                 decision_function_shape='ovr', degree=3,\n",
              "                                 gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                                 probability=False, random_state=42,\n",
              "                                 shrinking=True, tol=0.001, verbose=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4106bf240>,\n",
              "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4106bff28>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9u1j09o4liA",
        "colab_type": "text"
      },
      "source": [
        "## Results of Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpC9H3Yd4tON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c52a4f67-d06c-40f2-e724-d08b97189a5f"
      },
      "source": [
        "# What is the best estimator? \n",
        "rnd_search_cv.best_estimator_"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=4.998609717152554, break_ties=False, cache_size=200, class_weight=None,\n",
              "    coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "    gamma=0.001239742034078414, kernel='rbf', max_iter=-1, probability=False,\n",
              "    random_state=42, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pei90NV-4wDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c5af7f1-817f-40ba-815b-635841827bb9"
      },
      "source": [
        "# What is the accuracy score for this estimator?\n",
        "rnd_search_cv.best_score_"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8639927352502204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCddkYoV4z7Q",
        "colab_type": "text"
      },
      "source": [
        "This score is lower than the unregularized, kernelized SVM we trained on 1/6th of the available data. However, we need to recognize the fact that we're cross validating on only a dataset that is 10 time smaller than the one originally used for the kernelized SVM.\n",
        "\n",
        "This score will likely increase when the model is trained with the same hyperparameters on more data.\n",
        "\n",
        "The advantage of this approach is that cross validation is quicker, so we can train more models with different values for the hyperparameters. This speeds up the process of hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rYnLP0M5GmQ",
        "colab_type": "text"
      },
      "source": [
        "### Retraining Best Estimator\n",
        "\n",
        "Now that we've identified the best estimator, we can train it on the entire training set of 60,000 samples. \n",
        "\n",
        "This will take a lot of time to train. \n",
        "\n",
        "But the technique of tuning hyperparameters using a smaller subset of the training data is useful for models like SVM with high time complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyjpmEqY5PRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fdae8d17-8929-4bfc-81e9-2ce61db93c86"
      },
      "source": [
        "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=4.998609717152554, break_ties=False, cache_size=200, class_weight=None,\n",
              "    coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "    gamma=0.001239742034078414, kernel='rbf', max_iter=-1, probability=False,\n",
              "    random_state=42, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cCofphl5WKT",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e2weSgV5YLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "516e041e-2277-4b53-c789-1bae796232df"
      },
      "source": [
        "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ISxNHkQCOVi",
        "colab_type": "text"
      },
      "source": [
        "While this is a very good score, it is indicative of overfitting. The actual test set score will be lower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmbCmAxS5hD0",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUFT6s9h5lVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a09766ea-8378-40dd-88d6-5d1123a35b67"
      },
      "source": [
        "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIf6zoTG5yNt",
        "colab_type": "text"
      },
      "source": [
        "## Best Model\n",
        "\n",
        "The best SVM model found by the ML community uses the following hyperparameters \n",
        " - `C` = 5 \n",
        " - `gamma` = 0.005 \n",
        "\n",
        " It gives a test set accuracy of over 98%. \n",
        "\n",
        " We can find this by running randomized search for longer and on a larger part of the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w7gTg_05yKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiating SVC \n",
        "svc_best = SVC(kernel='rbf', gamma=0.005, C=5, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbIdMyB95yBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9f4a32c6-eef9-4e26-b472-561695efd211"
      },
      "source": [
        "# Training\n",
        "svc_best.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.005, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weCLn5Q67CPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b836155-2c19-4df8-dc3b-4dcee207eeba"
      },
      "source": [
        "# Evaluating on Training Data\n",
        "accuracy_score(y_train, svc_best.predict(X_train_scaled))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999833333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EJl6GAa7Gmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e1aa9b9-437b-4860-f65b-0ac1578e6987"
      },
      "source": [
        "# Evaluating on Test Data\n",
        "accuracy_score(y_test, svc_best.predict(X_test_scaled))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjZMaKQE7rKz",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 8 - Linear SVC and SGD Classifier\n",
        "\n",
        "Train a `LinearSVC` on a linearly separable dataset.\n",
        "\n",
        "Then train an `SVC` and a `SGDClassifier` on the same dataset. \n",
        "\n",
        "See if you can get them to produce roughly the same model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE17ALxX7rJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# The iris dataset is linearly separable when transformed to a binary problem\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo1CUh6f7rHw",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnHxyysA7rF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading data\n",
        "iris = load_iris()\n",
        "\n",
        "# Extracting features and labels\n",
        "X = iris['data'][:, (2, 3)]   # Petal length and petal width\n",
        "y = iris['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUheTNMh7rCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setosa is one class, versicolor is another - disregard virginica\n",
        "\n",
        "# Extract indices of both setosa and versicolor flowers from labels\n",
        "setosa_or_versicolor = (y == 0) | (y == 1)\n",
        "\n",
        "# Use indices to extract corresponding features and labels\n",
        "X = X[setosa_or_versicolor]\n",
        "y = y[setosa_or_versicolor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk3xwDIR7rAU",
        "colab_type": "text"
      },
      "source": [
        "## Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJEIc7PG7q7t",
        "colab_type": "text"
      },
      "source": [
        "### Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fiev70M9kyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = 5    # Regularization -> higher C -> more regularization -> narrower margin \n",
        "alpha = 1 / (C * len(X))    # For SGD Classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uITYPcEZ-Q8H",
        "colab_type": "text"
      },
      "source": [
        "### Instantiating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YdY-Vd597sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiating different classifiers \n",
        "lin_clf = LinearSVC(loss='hinge', C=C, random_state=42)\n",
        "svm_clf = SVC(kernel='linear', C=C)\n",
        "sgd_clf = SGDClassifier(loss='hinge', learning_rate='constant', eta0=0.001, \n",
        "                        alpha=alpha, max_iter=1000, tol=1e-3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yK3aAEF99DZ",
        "colab_type": "text"
      },
      "source": [
        "### Scaling Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIqfu2CM-ULk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hYi6k72-YVq",
        "colab_type": "text"
      },
      "source": [
        "### Fitting Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CBdpLhX-Zkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9efe418a-5124-44b5-af2b-fd3c20f1c3e3"
      },
      "source": [
        "lin_clf.fit(X_train_scaled, y)\n",
        "svm_clf.fit(X_train_scaled, y)\n",
        "sgd_clf.fit(X_train_scaled, y)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.002, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='constant', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmpUF--v-eUK",
        "colab_type": "text"
      },
      "source": [
        "### Comparing Final Coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9VCqbJs-jG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d3a30d60-9f85-4e5f-e3cc-f1bb6278b6ab"
      },
      "source": [
        "print(\"LinearSVC\\n\", lin_clf.intercept_, lin_clf.coef_)\n",
        "print(\"SVC\\n\", svm_clf.intercept_, svm_clf.coef_)\n",
        "print(\"SGD (alpha = {:.5f})\\n\".format(sgd_clf.alpha), sgd_clf.intercept_, sgd_clf.coef_)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC\n",
            " [0.28474272] [[1.05364736 1.09903308]]\n",
            "SVC\n",
            " [0.31896852] [[1.1203284  1.02625193]]\n",
            "SGD (alpha = 0.00200)\n",
            " [0.117] [[0.77714169 0.72981762]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv_u1U-P-5gv",
        "colab_type": "text"
      },
      "source": [
        "## Plotting Decision Boundaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyc-Bp0E_BKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the slope and bias of each decision boundary\n",
        "w1 = -lin_clf.coef_[0, 0] / lin_clf.coef_[0, 1]\n",
        "b1 = -lin_clf.intercept_[0] / lin_clf.coef_[0, 1]\n",
        "\n",
        "w2 = -svm_clf.coef_[0, 0] / svm_clf.coef_[0, 1]\n",
        "b2 = -svm_clf.intercept_[0] / svm_clf.coef_[0, 1]\n",
        "\n",
        "w3 = -sgd_clf.coef_[0, 0] / sgd_clf.coef_[0, 1]\n",
        "b3 = -sgd_clf.intercept_[0] / sgd_clf.coef_[0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQoK9HD6A-XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the decision boundary lines back to the original scale \n",
        "line1 = scaler.inverse_transform([[-10, -10 * w1 + b1], [10, 10 * w1 + b1]])\n",
        "line2 = scaler.inverse_transform([[-10, -10 * w2 + b2], [10, 10 * w2 + b2]])\n",
        "line3 = scaler.inverse_transform([[-10, -10 * w3 + b3], [10, 10 * w3 + b3]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEhX6sokBB1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "ab9da7e0-3936-4df0-e0cf-fcebc3510921"
      },
      "source": [
        "# Plot all three decision boundaries \n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(line1[:, 0], line1[:, 1], 'k:', label='LinearSVC')\n",
        "plt.plot(line2[:, 0], line2[:, 1], 'b--', label='SVC')\n",
        "plt.plot(line3[:, 0], line3[:, 1], 'r-', label='SGDClassifier')\n",
        "\n",
        "# Plotting samples\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\") # label=\"Iris versicolor\"\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\") # label=\"Iris setosa\"\n",
        "\n",
        "# Annotating graph\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"upper center\", fontsize=14)\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqcAAAESCAYAAADACnxfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH5lWE1lD6KU",
        "colab_type": "text"
      },
      "source": [
        "# Exercises 1 - 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMTVLLoED8Xq",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1 \n",
        "\n",
        "What is the fundamental idea behind support vector machines?\n",
        "\n",
        "**SVM Classifiers**\n",
        "- SVM classifiers attempt to fit the widest possible street between samples of the two classes.\n",
        "- The classification boundary is fully supported or determined by the samples (or vectors) of the two classes that are closest to each other. \n",
        "- The goal is to have the largest possible margin between the classification boundary that separates the two classes and the training instances. \n",
        "- Classification can be of two types\n",
        "  - hard margin: the SVM classifier ensures that there are no margin violations, which often leads to a narrower margin. \n",
        "  - soft margin: SVM classifier allows some margin violations, leading to a wider margin. \n",
        "\n",
        "**SVM Regressors**\n",
        "- SVM will still attempt to fit the a hypothesis hyperplane to the data, and the hyperplane will still have a margin.\n",
        "- The goal is still, in part, to maximise the margin.\n",
        "- However, the regressor now tries to fit as many samples within the margin as possible. \n",
        "- Margin violations in case of the SVM regressor occur when samples are not present within the margin. \n",
        "\n",
        "**Kernel Trick**\n",
        "- SVMs can be used for both linearly separable and non-linearly separably classification and regression.\n",
        "- In the case of the latter, the SVM uses a kernel trick: low dimensional features are passd to a kernel function, which is used to compute the equivalent dot product of highly non-linear features (polynomial features, similarity features) without actually computing the values of the features in a higher dimensional space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XK1XUBfD_Kx",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "**What is a Support Vector?**\n",
        "\n",
        "The classification boundary/hypothesis function of a SVM is fully determined or supported by samples vectors of the input features that are on the edge of the margin or within the margin. These vectors are called support vectors. \n",
        "\n",
        "In the SVM margin-street analogy, vectors representing any samples **on** the street are the support vectors. \n",
        "\n",
        "- Decison boundary of an SVM classifier is not affected by any samples that aren't support vectors.\n",
        "- Predictions made by SVMs involve the support vectors, not the entire training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QVEKjkmGVbd",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "**Why is it important to scale inputs when using SVMs?**\n",
        "\n",
        "SVMs are highly sensitive to feature scaling and outliers. The goal of SVMs is to fit the largest possible street between classes (in a classification problem). If the features are not scaled, the SVM will tend to neglect small features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W86buqzGjvu",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 4\n",
        "\n",
        "**Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?**\n",
        "\n",
        "- SVM classifiers **cannot** output confidence scores or probabilities directly: by default, their output is always a class label. \n",
        "- SVMs can, however, output the distance between a test set instance and the decision boundary, which can be used as a confidence score.\n",
        "- Confidence score cannot be directly converted int oa probabilty.\n",
        "- In `sklearn`, if the `probability` argument is set to `True` when instantiating an `SVC`, the `SVC` will output a probability. But these probabilities will be derived using a `LogisticRegression` model which will have been using 5-fold cross validation on the training set, and will drastically slow down training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utAT26-fHbuK",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 5 \n",
        "\n",
        "Should you use the primal or dual form of the SVM problem to train a model on a training set with `m` = 1M instances, and `n` = 100s of features?\n",
        "\n",
        "When the number of features `n` is much larger than the number of instances `m`, it is more computationally efficient to use the **primal** form of the SVM.\n",
        "\n",
        "This is because the primal form has approximate complexity of $\\mathcal{O}(m)$, whereas the dual form has a time complexity between $\\mathcal{O}(m^2 \\times n)$ and $\\mathcal{O}(m^3 \\times n)$. \n",
        "\n",
        "This only applies to Linear SVCs. Kernelized SVCs can only use the dual form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z2TODdnIA4J",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 6  \n",
        "\n",
        "**Say you trained an SVM using the RBF kernel. It seems to underfit the training set. Should you increase or decrease `gamma`? What about `C`?\n",
        "\n",
        "Too much regularization.\n",
        "- Increase `C`\n",
        "- Increase `gamma`"
      ]
    }
  ]
}