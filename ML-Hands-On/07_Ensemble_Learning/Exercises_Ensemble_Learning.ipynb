{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands-on-ML-Ex-07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFaahuTJVTPs",
        "colab_type": "text"
      },
      "source": [
        "# Hands on Machine Learning - Chapter 07 - Ensemble Methods - Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV5TzqDfVaBY",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 8 - Voting Classifier\n",
        "\n",
        "Load the MNIST data and split it into training, test, and validation sets (50k/10k/10k). \n",
        "\n",
        "Then train various classifiers such as Random Forest classifier, an Extra Trees classifier, and an SVM.\n",
        "\n",
        "Next, try to combine them into an ensemble that outperforms them all on the validation set using a soft or hard voting classifier. \n",
        "\n",
        "Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkwaW348VzUC",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Loading `MNIST` Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvsOI6zoV1nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
        "\n",
        "# Multilayer Perceptron classifier from sklearn's neural network module\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToGhJwB3WrE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch the MNIST data with examples as 784-dimensional feature vectors\n",
        "mnist = fetch_openml(name='mnist_784', version=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjtTLs-0WrCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting into training/val and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(mnist.data, mnist.target, \n",
        "                                                            test_size=10000, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip-A7RQSWrA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Further splitting the training/val set into distinct training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, \n",
        "                                                  test_size=10000, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSui34puWq_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirming that train/test/val sets have the right number of samples \n",
        "NUM_TRAIN = 50000\n",
        "NUM_TEST = 10000\n",
        "NUM_VAL = 10000\n",
        "NUM_FEATURES = 784\n",
        "\n",
        "# Training set \n",
        "assert len(X_train) == NUM_TRAIN \n",
        "assert len(y_train) == NUM_TRAIN\n",
        "assert X_train.shape[-1] == NUM_FEATURES\n",
        "\n",
        "# Test set \n",
        "assert len(X_test) == NUM_TEST\n",
        "assert len(y_test) == NUM_TEST \n",
        "assert X_test.shape[-1] == NUM_FEATURES\n",
        "\n",
        "# Validation set \n",
        "assert len(X_val) == NUM_VAL\n",
        "assert len(y_val) == NUM_VAL\n",
        "assert X_val.shape[-1] == NUM_FEATURES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6oSeOcnWq8D",
        "colab_type": "text"
      },
      "source": [
        "## Part 2 - Training Individual Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrC4Q4poWq3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate\n",
        "svm_clf = LinearSVC(random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "et_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "mlp_clf = MLPClassifier(random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsxomB3YWq1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "a2dd7a6e-b6bb-42df-8445-30db30950603"
      },
      "source": [
        "# Combine into list \n",
        "estimators = [svm_clf, rf_clf, et_clf, mlp_clf]\n",
        "\n",
        "# Train all models individually\n",
        "for estimator in estimators:\n",
        "  print(\"Training estimator\", estimator)\n",
        "  estimator.fit(X_train, y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training estimator LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
            "          verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training estimator RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)\n",
            "Training estimator ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                     criterion='gini', max_depth=None, max_features='auto',\n",
            "                     max_leaf_nodes=None, max_samples=None,\n",
            "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                     min_samples_leaf=1, min_samples_split=2,\n",
            "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                     warm_start=False)\n",
            "Training estimator MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsMtNGb1WqzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "825abb7c-9d92-43e6-bfb4-dadfd0dcd43f"
      },
      "source": [
        "# Evaluating individual estimators on validation test \n",
        "[estimator.score(X_val, y_val) for estimator in estimators]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8397, 0.9692, 0.9715, 0.9639]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLE6YB1Uav7t",
        "colab_type": "text"
      },
      "source": [
        "Order of scores: `[SVM, RF, ET, MLP]`\n",
        "- SVM is outperformed by all other models, probably because a linear decision boundary introduces too much bias: it is not possible to fit a linear decision boundary that appropriately separates all 10 digits from each other.\n",
        "- RF has good performance. It minimises overfitting by decreasing variance and only slightly increasing bias by randomly sampling a subset of features from which to choose a random feature for making a split across a large number of `DecisionTreeClassifier`s with bagging. \n",
        "- ET introduces even more randomness by choosing a random threshold value for each feature at each split. Surprisingly, this leads to better performance compared to a random forest with the same number of trees. \n",
        "- MLP has a lot of non-linearity, and is our first (unofficial) deep learning model. So it outperforms SVM, but underperforms RF and ET because it is not an ensemble classifier, and thus does not benefit from 'the wisdom of the crowd'.\n",
        "\n",
        "\n",
        "Still keeping `LinearSVC` because it is very different from all other classifiers, and thus unlikely to make the same errors as them. As such, it may improve scores in an ensemble."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3jBMmjZWqxV",
        "colab_type": "text"
      },
      "source": [
        "## Part 3 - Ensemble Classifier - Hard Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2BxOMvYWqu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of tuples linking each estimator to a string of its name\n",
        "named_estimators = [\n",
        "        ('random_forest_clf', rf_clf), \n",
        "        ('extra_trees_clf', et_clf), \n",
        "        ('mlp_clf', mlp_clf),\n",
        "        ('svm_clf', svm_clf),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4l2blYgWqtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a hard voting classifier using this list of tuples\n",
        "voting_clf = VotingClassifier(named_estimators)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CITZaHEWqqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "298dce3a-6e91-4ff7-bb7f-9b02e76ea6fd"
      },
      "source": [
        "# Fit the voting classifier to data\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('random_forest_clf',\n",
              "                              RandomForestClassifier(bootstrap=True,\n",
              "                                                     ccp_alpha=0.0,\n",
              "                                                     class_weight=None,\n",
              "                                                     criterion='gini',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features='auto',\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     max_samples=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_impurity_split=None,\n",
              "                                                     min_samples_leaf=1,\n",
              "                                                     min_samples_split=2,\n",
              "                                                     min_weight_fraction_leaf=0.0,\n",
              "                                                     n_estimators=100,\n",
              "                                                     n_jobs...\n",
              "                                            shuffle=True, solver='adam',\n",
              "                                            tol=0.0001, validation_fraction=0.1,\n",
              "                                            verbose=False, warm_start=False)),\n",
              "                             ('svm_clf',\n",
              "                              LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                                        fit_intercept=True, intercept_scaling=1,\n",
              "                                        loss='squared_hinge', max_iter=1000,\n",
              "                                        multi_class='ovr', penalty='l2',\n",
              "                                        random_state=42, tol=0.0001,\n",
              "                                        verbose=0))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYygrGROcCwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "537bb235-568b-44bc-b703-326b90159f1c"
      },
      "source": [
        "# Evaluating on validation set\n",
        "voting_clf.score(X_val, y_val)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-5QYoxvWqoJ",
        "colab_type": "text"
      },
      "source": [
        "### Effect of SVM \n",
        "\n",
        "Does removing the `LinearSVC` from the ensemble improve performance? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zeMZcUXla4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "50cadec4-77fe-4fb9-f3e0-898df2851035"
      },
      "source": [
        "voting_clf.set_params(svm_clf=None)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('random_forest_clf',\n",
              "                              RandomForestClassifier(bootstrap=True,\n",
              "                                                     ccp_alpha=0.0,\n",
              "                                                     class_weight=None,\n",
              "                                                     criterion='gini',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features='auto',\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     max_samples=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_impurity_split=None,\n",
              "                                                     min_samples_leaf=1,\n",
              "                                                     min_samples_split=2,\n",
              "                                                     min_weight_fraction_leaf=0.0,\n",
              "                                                     n_estimators=100,\n",
              "                                                     n_jobs...\n",
              "                                            hidden_layer_sizes=(100,),\n",
              "                                            learning_rate='constant',\n",
              "                                            learning_rate_init=0.001,\n",
              "                                            max_fun=15000, max_iter=200,\n",
              "                                            momentum=0.9, n_iter_no_change=10,\n",
              "                                            nesterovs_momentum=True,\n",
              "                                            power_t=0.5, random_state=42,\n",
              "                                            shuffle=True, solver='adam',\n",
              "                                            tol=0.0001, validation_fraction=0.1,\n",
              "                                            verbose=False, warm_start=False)),\n",
              "                             ('svm_clf', None)],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCo2aLBEWqhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "1852f32f-4ba8-4331-da83-69929e8b8451"
      },
      "source": [
        "# This will have updated the list of estimators in the voting classifier\n",
        "voting_clf.estimators"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('random_forest_clf',\n",
              "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                         criterion='gini', max_depth=None, max_features='auto',\n",
              "                         max_leaf_nodes=None, max_samples=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=2,\n",
              "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                         n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                         warm_start=False)),\n",
              " ('extra_trees_clf',\n",
              "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)),\n",
              " ('mlp_clf',\n",
              "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "                beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "                hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "                learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "                momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "                power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
              "                tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "                warm_start=False))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tOHQBJQWqc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "783940ba-f605-40a7-c25f-ba0436ae03cb"
      },
      "source": [
        "# But the list of traind estimators has not been updated!\n",
        "voting_clf.estimators_    # _ at the end means list of trained estimators"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                        warm_start=False),\n",
              " ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                      criterion='gini', max_depth=None, max_features='auto',\n",
              "                      max_leaf_nodes=None, max_samples=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False),\n",
              " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "               power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
              "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "               warm_start=False),\n",
              " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "           multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
              "           verbose=0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUSuX5_9lxxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete the svm classifier from the list of trained classifiers\n",
        "del voting_clf.estimators_[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_y0Q3WpWqYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "155fd9e1-77ba-48f1-d911-ffe59caf9365"
      },
      "source": [
        "# Confirming that I deleted the right estimator\n",
        "voting_clf.estimators_"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                        warm_start=False),\n",
              " ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                      criterion='gini', max_depth=None, max_features='auto',\n",
              "                      max_leaf_nodes=None, max_samples=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False),\n",
              " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "               power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
              "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "               warm_start=False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flW2owP0WqV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a17bd0e8-344f-4b91-f04f-da72669ffc78"
      },
      "source": [
        "# Did it improve validation score?\n",
        "voting_clf.score(X_val, y_val)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cWjWeSAWqTj",
        "colab_type": "text"
      },
      "source": [
        "## Part 4 - Soft Voting Classifier\n",
        "\n",
        "A soft voting classifier will make predictions based on class probabilities rather than just majority class votes. The predicted class for a given example is the one with the highest predicted class probability averaged across all classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEeSN5XpWqRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simply set voting parameter to soft \n",
        "voting_clf.voting = 'soft'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfU8-AGsWqOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f5510f0-7084-43f0-e0ac-8e3ccbc9b149"
      },
      "source": [
        "# Evaluate on the validation set again\n",
        "voting_clf.score(X_val, y_val)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUKZDAiVWqM6",
        "colab_type": "text"
      },
      "source": [
        "## Part 5 - Test Set Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqRdBE3MWqKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resetting voting method to `hard` because majority votes led to better val set performance\n",
        "voting_clf.voting = 'hard'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGZDgcsqWqH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17a50f81-9759-4bc5-8b59-7ead2d261d33"
      },
      "source": [
        "# Evaluate on the test set\n",
        "voting_clf.score(X_test, y_test)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-YZqmikWqFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8206ce6-0300-40fc-f3bd-30a3d389932e"
      },
      "source": [
        "# Compare with results of individual estimators\n",
        "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwA_P3veWqDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitted_estimators = voting_clf.estimators_[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2b00CEHnIJR",
        "colab_type": "text"
      },
      "source": [
        "Throughout this exercise, I have been unable to get non-zero scores for the fitted estimators through list comprehension as well as through for loops. \n",
        "\n",
        "I found that \n",
        "- soft voting classifiers do not always outperform hard voting classifiers. In this case, a hard voting classifier had a validation set score of 0.9736, whereas a soft voting classifier had a score of 0.97.\n",
        "- removing the `LinearSVC` classifier improved validation set performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gSIudnzlnHb6"
      },
      "source": [
        "# Exercise 9 - Stacking Ensemble\n",
        "\n",
        "Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions. \n",
        "\n",
        "Each training instance is a vector containing the set of predictions from all your classifiers for an image and the tartget is the image's class. \n",
        "\n",
        "This is a **blender**, and together with the classifiers, it forms a stacking ensemble. \n",
        "\n",
        "Evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensembles predictions. \n",
        "\n",
        "How does it compare to the voting classifier you trained earlier?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFwzXgTv1ZYU",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Individual Classifiers \n",
        "\n",
        "Will recreate and retrain the 4 classifiers from the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Aivbxp1fGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make new classifiers\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = LinearSVC(random_state=42)\n",
        "mlp_clf = MLPClassifier(random_state=42)\n",
        "extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcFVgNUR1fDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wrap them up in a list\n",
        "estimators = [rnd_clf, mlp_clf, extra_trees_clf, svm_clf]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IvT4jQV1fAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6f5abc3c-3ab3-4789-923f-11113013c2f1"
      },
      "source": [
        "# Fit them to the training data\n",
        "for estimator in estimators:\n",
        "  estimator.fit(X_train, y_train)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxZf0w3qWe9S",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Predictions as Features\n",
        "\n",
        "- Ensemble voting classifier consists of four classifiers (before dropping the SVM).\n",
        "- Each of these classifiers will be used to make a prediction (a predicted class from `0` - `9`). \n",
        "- This means the predictions will be a 4-D vector `[pred_1, pred_2, pred_3, pred_4]`.\n",
        "- There will be one such prediction for each validation set example `m`.\n",
        "  - Not the training set. This will ensure that predictions made by the first layer of estimators are 'clean'.\n",
        "- So the matrix of predictions will have shape `(m, 3)`. \n",
        "- These predictions will be used as features for training a **meta model**: a model that learns how best to combine predictions made by individual predictors so that the ensemble's prediction is as accurate as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHo2hrpl14bJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One row per validation set sample, one column per estimator\n",
        "NUM_ESTIMATORS = len(estimators)\n",
        "X_val_predictions = np.empty((NUM_VAL, NUM_ESTIMATORS), dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4dy0Ogy2HDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store predictions for each validation set sample in the predictions array\n",
        "for index, estimator in enumerate(estimators):\n",
        "  X_val_predictions[:, index] = estimator.predict(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Te9YfEO2Oj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b67fb858-520a-44b8-8f1f-93070c286012"
      },
      "source": [
        "# Confirming predictions\n",
        "X_val_predictions"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 5., 5., 8.],\n",
              "       [8., 8., 8., 8.],\n",
              "       [2., 2., 2., 2.],\n",
              "       ...,\n",
              "       [7., 7., 7., 7.],\n",
              "       [6., 6., 6., 6.],\n",
              "       [7., 7., 7., 7.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlbMRGrC2T4R",
        "colab_type": "text"
      },
      "source": [
        "## Part 3 - Training Meta Model \n",
        "\n",
        "Will create a `RandomForestClassifier` that will use the predictions made on the validation set as training data to learn the mapping from validation set predictions to validation set classes.\n",
        "\n",
        "Since we don't have a hold-out validation set, and since the random forest estimator uses bagging (meaning 37% of samples, on average, are never seen during training), we can use out of bag evaluation to get validation scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJGphodf2fdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moPzGu0h2w9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "047bb746-b06c-438b-ad77-1c429dd85a88"
      },
      "source": [
        "# Fit to the data\n",
        "rnd_forest_blender.fit(X_val_predictions, y_val)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=True, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI6Vg2_u204Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca72649a-7223-4bc3-e8bb-b47a94dc7b18"
      },
      "source": [
        "# What is the validation set score?\n",
        "rnd_forest_blender.oob_score_"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MjFzOOG248E",
        "colab_type": "text"
      },
      "source": [
        "## Part 4 - Evaluating Meta Model \n",
        "\n",
        "To evaluate the stacked model, will have to create predictions for samples on the test set using the ensemble's predictors.\n",
        "\n",
        "These predictions will then be fed to the trained meta model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxKEbSBN40rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating array for test set predictions\n",
        "X_test_predictions = np.empty((NUM_TEST, NUM_ESTIMATORS), dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgUviB7C44KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing predictions\n",
        "for index, estimator in enumerate(estimators):\n",
        "  X_test_predictions[:, index] = estimator.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od3-2NJg5Epk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use these as features for the blender \n",
        "y_pred = rnd_forest_blender.predict(X_test_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQwSjlDg5Oyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c7b82f5-3ddf-42c6-a1ef-8db3b62e9701"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UVNL5F55QcT",
        "colab_type": "text"
      },
      "source": [
        "- Even on the validation set, the random forest blender metamodel did not do as well as the hard and soft voting classifiers.\n",
        "- This trend was also observed in the test set results.\n",
        "- Which goes to show that stacking may not always improve results.\n",
        "- Sometimes, a simple hard voting classifier may be the best solution for aggregating the results of an ensemble classifier."
      ]
    }
  ]
}